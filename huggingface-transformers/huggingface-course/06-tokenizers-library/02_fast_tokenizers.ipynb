{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/transformers-research-and-practice/blob/main/huggingface-transformers/huggingface-course/06-tokenizers-library/02_fast_tokenizers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_wN2rfXthHb"
      },
      "source": [
        "## Fast tokenizers' special powers (PyTorch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ocv4iRxthHd"
      },
      "source": [
        "Install the Transformers, Datasets, and Evaluate libraries to run this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXjQCR64thHd"
      },
      "outputs": [],
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UPWDbkQuthHe",
        "outputId": "9f03e8a3-1df2-485c-f67d-63a4b33ee76d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'transformers.tokenization_utils_base.BatchEncoding'>\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "example = \"My name is Sylvain and I work at Hugging Face in Brooklyn.\"\n",
        "encoding = tokenizer(example)\n",
        "print(type(encoding))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LFneLcuIthHg",
        "outputId": "d7fef93a-89bf-420c-997d-e9e7bcceaf1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "tokenizer.is_fast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "txiu0iSQthHg",
        "outputId": "b8bc466c-a780-485d-a0eb-832c33e37fcc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "encoding.is_fast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4ROe3dIgthHg",
        "outputId": "581e4c8a-8ee5-4d4e-e3c0-a6d1f2b0a5d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'My',\n",
              " 'name',\n",
              " 'is',\n",
              " 'S',\n",
              " '##yl',\n",
              " '##va',\n",
              " '##in',\n",
              " 'and',\n",
              " 'I',\n",
              " 'work',\n",
              " 'at',\n",
              " 'Hu',\n",
              " '##gging',\n",
              " 'Face',\n",
              " 'in',\n",
              " 'Brooklyn',\n",
              " '.',\n",
              " '[SEP]']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Letâ€™s see what a fast tokenizer enables us to do\n",
        "encoding.tokens()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "yy15wgnUthHh",
        "outputId": "60936333-d9bf-4fcb-d086-1c8ff98a88ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, 0, 1, 2, 3, 3, 3, 3, 4, 5, 6, 7, 8, 8, 9, 10, 11, 12, None]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "encoding.word_ids()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoding.token_type_ids"
      ],
      "metadata": {
        "id": "k-sfBBaAwoRN",
        "outputId": "2692a327-45ec-4d75-dec3-796b9b106ac0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bQmt7rXrthHh",
        "outputId": "410566bf-7d3e-48b9-9c20-3e3de4ab41ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Sylvain'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Lastly, we can map any word or token to characters in the original text, and vice versa\n",
        "start, end = encoding.word_to_chars(3)\n",
        "example[start:end]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## token-classification pipeline"
      ],
      "metadata": {
        "id": "8faQgy36rRef"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhf1_3VdthHi"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "token_classifier = pipeline(\"token-classification\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_classifier(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")"
      ],
      "metadata": {
        "id": "Gygqcg3Ur4uN",
        "outputId": "0bc7f7f6-4f27-4e81-f1aa-af57f2070a77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity': 'I-PER',\n",
              "  'score': np.float32(0.99938285),\n",
              "  'index': 4,\n",
              "  'word': 'S',\n",
              "  'start': 11,\n",
              "  'end': 12},\n",
              " {'entity': 'I-PER',\n",
              "  'score': np.float32(0.99815494),\n",
              "  'index': 5,\n",
              "  'word': '##yl',\n",
              "  'start': 12,\n",
              "  'end': 14},\n",
              " {'entity': 'I-PER',\n",
              "  'score': np.float32(0.99590707),\n",
              "  'index': 6,\n",
              "  'word': '##va',\n",
              "  'start': 14,\n",
              "  'end': 16},\n",
              " {'entity': 'I-PER',\n",
              "  'score': np.float32(0.99923277),\n",
              "  'index': 7,\n",
              "  'word': '##in',\n",
              "  'start': 16,\n",
              "  'end': 18},\n",
              " {'entity': 'I-ORG',\n",
              "  'score': np.float32(0.9738931),\n",
              "  'index': 12,\n",
              "  'word': 'Hu',\n",
              "  'start': 33,\n",
              "  'end': 35},\n",
              " {'entity': 'I-ORG',\n",
              "  'score': np.float32(0.976115),\n",
              "  'index': 13,\n",
              "  'word': '##gging',\n",
              "  'start': 35,\n",
              "  'end': 40},\n",
              " {'entity': 'I-ORG',\n",
              "  'score': np.float32(0.9887976),\n",
              "  'index': 14,\n",
              "  'word': 'Face',\n",
              "  'start': 41,\n",
              "  'end': 45},\n",
              " {'entity': 'I-LOC',\n",
              "  'score': np.float32(0.9932106),\n",
              "  'index': 16,\n",
              "  'word': 'Brooklyn',\n",
              "  'start': 49,\n",
              "  'end': 57}]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ppiK6USsthHi"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "token_classifier = pipeline(\"token-classification\", aggregation_strategy=\"simple\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_classifier(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")"
      ],
      "metadata": {
        "id": "QqDEEQD4r9Zy",
        "outputId": "cf989442-6a97-4e87-c7fd-0d56f03c7257",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'PER',\n",
              "  'score': np.float32(0.9981694),\n",
              "  'word': 'Sylvain',\n",
              "  'start': 11,\n",
              "  'end': 18},\n",
              " {'entity_group': 'ORG',\n",
              "  'score': np.float32(0.9796019),\n",
              "  'word': 'Hugging Face',\n",
              "  'start': 33,\n",
              "  'end': 45},\n",
              " {'entity_group': 'LOC',\n",
              "  'score': np.float32(0.9932106),\n",
              "  'word': 'Brooklyn',\n",
              "  'start': 49,\n",
              "  'end': 57}]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_classifier = pipeline(\"token-classification\", aggregation_strategy=\"first\")"
      ],
      "metadata": {
        "id": "0A8lJFv0sNgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_classifier(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")"
      ],
      "metadata": {
        "id": "MNOk4jJlsUuy",
        "outputId": "e21c5bf1-0fa4-4eae-b38b-b8a088481ecb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'PER',\n",
              "  'score': np.float32(0.99938285),\n",
              "  'word': 'Sylvain',\n",
              "  'start': 11,\n",
              "  'end': 18},\n",
              " {'entity_group': 'ORG',\n",
              "  'score': np.float32(0.98134536),\n",
              "  'word': 'Hugging Face',\n",
              "  'start': 33,\n",
              "  'end': 45},\n",
              " {'entity_group': 'LOC',\n",
              "  'score': np.float32(0.9932106),\n",
              "  'word': 'Brooklyn',\n",
              "  'start': 49,\n",
              "  'end': 57}]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_classifier = pipeline(\"token-classification\", aggregation_strategy=\"max\")"
      ],
      "metadata": {
        "id": "Mo2vGz3FsY7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_classifier(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")"
      ],
      "metadata": {
        "id": "7-78jX2fs-Rb",
        "outputId": "860f475b-8224-4470-95b8-c627eaab1c89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'PER',\n",
              "  'score': np.float32(0.99938285),\n",
              "  'word': 'Sylvain',\n",
              "  'start': 11,\n",
              "  'end': 18},\n",
              " {'entity_group': 'ORG',\n",
              "  'score': np.float32(0.9824563),\n",
              "  'word': 'Hugging Face',\n",
              "  'start': 33,\n",
              "  'end': 45},\n",
              " {'entity_group': 'LOC',\n",
              "  'score': np.float32(0.9932106),\n",
              "  'word': 'Brooklyn',\n",
              "  'start': 49,\n",
              "  'end': 57}]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_classifier = pipeline(\"token-classification\", aggregation_strategy=\"average\")"
      ],
      "metadata": {
        "id": "7eNnPgQDtK_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_classifier(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")"
      ],
      "metadata": {
        "id": "iE-NsIqytURl",
        "outputId": "88131a03-70b3-48b7-ed77-e08b916368ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'PER',\n",
              "  'score': np.float32(0.9981694),\n",
              "  'word': 'Sylvain',\n",
              "  'start': 11,\n",
              "  'end': 18},\n",
              " {'entity_group': 'ORG',\n",
              "  'score': np.float32(0.9819008),\n",
              "  'word': 'Hugging Face',\n",
              "  'start': 33,\n",
              "  'end': 45},\n",
              " {'entity_group': 'LOC',\n",
              "  'score': np.float32(0.9932106),\n",
              "  'word': 'Brooklyn',\n",
              "  'start': 49,\n",
              "  'end': 57}]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## From inputs to predictions"
      ],
      "metadata": {
        "id": "HsMDjTSNtl6P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OO6dILIHthHj"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "\n",
        "model_checkpoint = \"dbmdz/bert-large-cased-finetuned-conll03-english\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint)\n",
        "\n",
        "example = \"My name is Sylvain and I work at Hugging Face in Brooklyn.\"\n",
        "inputs = tokenizer(example, return_tensors=\"pt\")\n",
        "outputs = model(**inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "fB8giv_XthHk",
        "outputId": "191d4b14-f236-4e17-eb43-3a9c670ee3de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 19])\n",
            "torch.Size([1, 19, 9])\n"
          ]
        }
      ],
      "source": [
        "# We have a batch with 1 sequence of 19 tokens and the model has 9 different labels\n",
        "print(inputs[\"input_ids\"].shape)\n",
        "print(outputs.logits.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "k4mEdJeLthHk",
        "outputId": "31aa8b9a-cc80-4d98-d9e4-6f635334e201",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0, 0, 4, 4, 4, 4, 0, 0, 0, 0, 6, 6, 6, 0, 8, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# we use a softmax function to convert those logits to probabilities\n",
        "probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)[0].tolist()\n",
        "predictions = outputs.logits.argmax(dim=-1)[0].tolist()\n",
        "print(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "D30QxjBnthHk",
        "outputId": "ad1dcaec-cf15-41d5-fae3-1085c8ddfa6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'O',\n",
              " 1: 'B-MISC',\n",
              " 2: 'I-MISC',\n",
              " 3: 'B-PER',\n",
              " 4: 'I-PER',\n",
              " 5: 'B-ORG',\n",
              " 6: 'I-ORG',\n",
              " 7: 'B-LOC',\n",
              " 8: 'I-LOC'}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "# the mapping of indexes to labels that we can use to make sense of the predictions\n",
        "model.config.id2label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ds_3H0N1thHk",
        "outputId": "376404bf-f91d-4b06-c3c4-bf703ac0978e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'entity': 'I-PER', 'score': 0.9993828535079956, 'word': 'S'}, {'entity': 'I-PER', 'score': 0.9981548190116882, 'word': '##yl'}, {'entity': 'I-PER', 'score': 0.995907187461853, 'word': '##va'}, {'entity': 'I-PER', 'score': 0.9992327690124512, 'word': '##in'}, {'entity': 'I-ORG', 'score': 0.9738931059837341, 'word': 'Hu'}, {'entity': 'I-ORG', 'score': 0.9761149883270264, 'word': '##gging'}, {'entity': 'I-ORG', 'score': 0.9887974858283997, 'word': 'Face'}, {'entity': 'I-LOC', 'score': 0.99321049451828, 'word': 'Brooklyn'}]\n"
          ]
        }
      ],
      "source": [
        "# With this map, we are ready to reproduce (almost entirely) the results of the first pipeline\n",
        "results = []\n",
        "tokens = inputs.tokens()\n",
        "\n",
        "for idx, pred in enumerate(predictions):\n",
        "    label = model.config.id2label[pred]\n",
        "    if label != \"O\":\n",
        "        results.append(\n",
        "            {\"entity\": label, \"score\": probabilities[idx][pred], \"word\": tokens[idx]}\n",
        "        )\n",
        "\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "m2udnmn8thHk",
        "outputId": "6d3692f7-8a27-4fcf-87bc-9ee3158081ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 0),\n",
              " (0, 2),\n",
              " (3, 7),\n",
              " (8, 10),\n",
              " (11, 12),\n",
              " (12, 14),\n",
              " (14, 16),\n",
              " (16, 18),\n",
              " (19, 22),\n",
              " (23, 24),\n",
              " (25, 29),\n",
              " (30, 32),\n",
              " (33, 35),\n",
              " (35, 40),\n",
              " (41, 45),\n",
              " (46, 48),\n",
              " (49, 57),\n",
              " (57, 58),\n",
              " (0, 0)]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "inputs_with_offsets = tokenizer(example, return_offsets_mapping=True)\n",
        "inputs_with_offsets[\"offset_mapping\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "xHloPkWqthHk",
        "outputId": "c84d4401-5bb1-48a9-b9b2-2465656a0590",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'yl'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "example[12:14]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "y9_3ndMSthHk",
        "outputId": "158b30d5-f42d-4bcb-ef69-6f2afd8425ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'entity': 'I-PER', 'score': 0.9993828535079956, 'word': 'S', 'start': 11, 'end': 12}, {'entity': 'I-PER', 'score': 0.9981548190116882, 'word': '##yl', 'start': 12, 'end': 14}, {'entity': 'I-PER', 'score': 0.995907187461853, 'word': '##va', 'start': 14, 'end': 16}, {'entity': 'I-PER', 'score': 0.9992327690124512, 'word': '##in', 'start': 16, 'end': 18}, {'entity': 'I-ORG', 'score': 0.9738931059837341, 'word': 'Hu', 'start': 33, 'end': 35}, {'entity': 'I-ORG', 'score': 0.9761149883270264, 'word': '##gging', 'start': 35, 'end': 40}, {'entity': 'I-ORG', 'score': 0.9887974858283997, 'word': 'Face', 'start': 41, 'end': 45}, {'entity': 'I-LOC', 'score': 0.99321049451828, 'word': 'Brooklyn', 'start': 49, 'end': 57}]\n"
          ]
        }
      ],
      "source": [
        "# Using this, we can now complete the previous results\n",
        "results = []\n",
        "inputs_with_offsets = tokenizer(example, return_offsets_mapping=True)\n",
        "tokens = inputs_with_offsets.tokens()\n",
        "offsets = inputs_with_offsets[\"offset_mapping\"]\n",
        "\n",
        "for idx, pred in enumerate(predictions):\n",
        "    label = model.config.id2label[pred]\n",
        "    if label != \"O\":\n",
        "        start, end = offsets[idx]\n",
        "        results.append(\n",
        "            {\n",
        "                \"entity\": label,\n",
        "                \"score\": probabilities[idx][pred],\n",
        "                \"word\": tokens[idx],\n",
        "                \"start\": start,\n",
        "                \"end\": end,\n",
        "            }\n",
        "        )\n",
        "\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Grouping entities"
      ],
      "metadata": {
        "id": "WLQrWJx9wNtZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "SGVbfcqbthHk",
        "outputId": "396d13a2-b195-4159-8d23-23317ac9ce33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hugging Face'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "# Using the offsets to determine the start and end keys for each entity is handy\n",
        "example[33:45]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example[11:18]"
      ],
      "metadata": {
        "id": "fmlSxHMevrOp",
        "outputId": "e2a33296-933a-4f03-9290-576948c98c1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Sylvain'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example[49:57]"
      ],
      "metadata": {
        "id": "EiafPrOxv8c-",
        "outputId": "af70f924-fb11-4f0b-9cda-73cb9e99c631",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Brooklyn'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "RiMi9OtYthHk",
        "outputId": "08951364-8e3e-4b5b-8497-d8f7569f7284",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'entity_group': 'PER', 'score': 0.998169407248497, 'word': 'Sylvain', 'start': 11, 'end': 18}, {'entity_group': 'ORG', 'score': 0.9796018600463867, 'word': 'Hugging Face', 'start': 33, 'end': 45}, {'entity_group': 'LOC', 'score': 0.99321049451828, 'word': 'Brooklyn', 'start': 49, 'end': 57}]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "results = []\n",
        "inputs_with_offsets = tokenizer(example, return_offsets_mapping=True)\n",
        "tokens = inputs_with_offsets.tokens()\n",
        "offsets = inputs_with_offsets[\"offset_mapping\"]\n",
        "\n",
        "idx = 0\n",
        "while idx < len(predictions):\n",
        "    pred = predictions[idx]\n",
        "    label = model.config.id2label[pred]\n",
        "    if label != \"O\":\n",
        "        # Remove the B- or I-\n",
        "        label = label[2:]\n",
        "        start, _ = offsets[idx]\n",
        "\n",
        "        # Grab all the tokens labeled with I-label\n",
        "        all_scores = []\n",
        "        while (\n",
        "            idx < len(predictions)\n",
        "            and model.config.id2label[predictions[idx]] == f\"I-{label}\"\n",
        "        ):\n",
        "            all_scores.append(probabilities[idx][pred])\n",
        "            _, end = offsets[idx]\n",
        "            idx += 1\n",
        "\n",
        "        # The score is the mean of all the scores of the tokens in that grouped entity\n",
        "        score = np.mean(all_scores).item()\n",
        "        word = example[start:end]\n",
        "        results.append(\n",
        "            {\n",
        "                \"entity_group\": label,\n",
        "                \"score\": score,\n",
        "                \"word\": word,\n",
        "                \"start\": start,\n",
        "                \"end\": end,\n",
        "            }\n",
        "        )\n",
        "    idx += 1\n",
        "\n",
        "print(results)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}