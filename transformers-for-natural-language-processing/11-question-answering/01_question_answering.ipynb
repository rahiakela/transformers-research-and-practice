{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01-question-answering.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO1TYOTAutHk4pJ457041ez",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/transformers-research-and-practice/blob/main/transformers-for-natural-language-processing/11-question-answering/01_question_answering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Question Answering"
      ],
      "metadata": {
        "id": "KP3roeuLW65S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will focus on using question-answering in an open environment where the questions were\n",
        "not prepared beforehand. Transformer models require help from other NLP tasks and classical\n",
        "programs. \n",
        "\n",
        "We will explore some methods to give an idea of how to combine tasks to reach the goal of a project:\n",
        "\n",
        "* Method 0 explores a trial and error approach of asking questions randomly.\n",
        "* Method 1 introduces NER to help prepare the question-answering tasks.\n",
        "* Method 2 tries to help the default transformer with an ELECTRA transformer model. It\n",
        "also introduces SRL to help the transformer prepare questions.\n",
        "\n",
        "The introduction to these three methods shows that a single question-answering method will\n",
        "not work for high-profile corporate projects. Adding NER and SRL will improve the linguistic\n",
        "intelligence of a transformer agent solution."
      ],
      "metadata": {
        "id": "N0fD5DsRXEwa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "WcCJ-J45XWnw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install transformers[sentencepiece]"
      ],
      "metadata": {
        "id": "gdBM6YwWXV1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "qibF5Zw6Xb-D"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Method 0: Trial and error"
      ],
      "metadata": {
        "id": "HNN6e284Y0sK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_qa = pipeline(\"question-answering\")"
      ],
      "metadata": {
        "id": "fcSB0F47Y60B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence = \"\"\"The traffic began to slow down on Pioneer Boulevard in Los Angeles, making it difficult to get out of the city. However, WBGO was\n",
        "playing some cool jazz, and the weather was cool, making it rather pleasant to be making it out of the city on this Friday afternoon. \n",
        "Nat King Cole was singing as Jo, and Maria slowly made their way out of LA and drove toward Barstow. They planned to get to Las Vegas early enough in the\n",
        "evening to have a nice dinner and go see a show.\"\"\"\n",
        "\n",
        "nlp_qa(context=sequence, question=\"Where is Pioneer Boulevard?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-i9EYuiZCie",
        "outputId": "f1bbba4c-bef3-4a3d-8177-d62fd5af7e7c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': 'Los Angeles', 'end': 66, 'score': 0.9882006645202637, 'start': 55}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Method 1: NER first"
      ],
      "metadata": {
        "id": "c65RT6jRZ2mQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using NER to find questions\n",
        "nlp_ner = pipeline(\"ner\")"
      ],
      "metadata": {
        "id": "zjUHd9itZ3ZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(nlp_ner(sequence))"
      ],
      "metadata": {
        "id": "5OXSarRgVWQS",
        "outputId": "d440aeea-668a-4a73-88f2-1716c830c9f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'entity': 'I-LOC', 'score': 0.97324556, 'index': 8, 'word': 'Pioneer', 'start': 34, 'end': 41}, {'entity': 'I-LOC', 'score': 0.99442816, 'index': 9, 'word': 'Boulevard', 'start': 42, 'end': 51}, {'entity': 'I-LOC', 'score': 0.9995722, 'index': 11, 'word': 'Los', 'start': 55, 'end': 58}, {'entity': 'I-LOC', 'score': 0.99956805, 'index': 12, 'word': 'Angeles', 'start': 59, 'end': 66}, {'entity': 'I-ORG', 'score': 0.991907, 'index': 26, 'word': 'W', 'start': 121, 'end': 122}, {'entity': 'I-ORG', 'score': 0.9905408, 'index': 27, 'word': '##B', 'start': 122, 'end': 123}, {'entity': 'I-ORG', 'score': 0.988502, 'index': 28, 'word': '##G', 'start': 123, 'end': 124}, {'entity': 'I-ORG', 'score': 0.9714335, 'index': 29, 'word': '##O', 'start': 124, 'end': 125}, {'entity': 'I-PER', 'score': 0.9980508, 'index': 59, 'word': 'Nat', 'start': 265, 'end': 268}, {'entity': 'I-PER', 'score': 0.9984724, 'index': 60, 'word': 'King', 'start': 269, 'end': 273}, {'entity': 'I-PER', 'score': 0.99907494, 'index': 61, 'word': 'Cole', 'start': 274, 'end': 278}, {'entity': 'I-PER', 'score': 0.99590236, 'index': 65, 'word': 'Jo', 'start': 294, 'end': 296}, {'entity': 'I-PER', 'score': 0.9987363, 'index': 68, 'word': 'Maria', 'start': 302, 'end': 307}, {'entity': 'I-LOC', 'score': 0.99796426, 'index': 75, 'word': 'LA', 'start': 337, 'end': 339}, {'entity': 'I-LOC', 'score': 0.99656504, 'index': 79, 'word': 'Bar', 'start': 357, 'end': 360}, {'entity': 'I-LOC', 'score': 0.84329575, 'index': 80, 'word': '##sto', 'start': 360, 'end': 363}, {'entity': 'I-LOC', 'score': 0.99114674, 'index': 81, 'word': '##w', 'start': 363, 'end': 364}, {'entity': 'I-LOC', 'score': 0.9993801, 'index': 88, 'word': 'Las', 'start': 389, 'end': 392}, {'entity': 'I-LOC', 'score': 0.99897325, 'index': 89, 'word': 'Vegas', 'start': 393, 'end': 398}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s ask our transformer two types of questions:\n",
        "* Questions related to locations\n",
        "* Questions related to persons"
      ],
      "metadata": {
        "id": "kYEIdjw2XNL5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Location entity questions"
      ],
      "metadata": {
        "id": "2ptbTfQuYRgi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_qa = pipeline(\"question-answering\")"
      ],
      "metadata": {
        "id": "7f9MEKbzXQn3",
        "outputId": "38d8d99b-3c8b-4a22-f37c-22c5ace40e44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-cased-distilled-squad (https://huggingface.co/distilbert-base-cased-distilled-squad)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Question 1.\", nlp_qa(context=sequence, question=\"Where is Pioneer Boulevard?\"))\n",
        "print(\"Question 2.\", nlp_qa(context=sequence, question=\"Where is Los Angeles located?\"))\n",
        "print(\"Question 3.\", nlp_qa(context=sequence, question=\"Where is LA?\"))\n",
        "print(\"Question 4.\", nlp_qa(context=sequence, question=\"Where is Barstow?\"))\n",
        "print(\"Question 5.\", nlp_qa(context=sequence, question=\"Where is Las Vegas located?\"))"
      ],
      "metadata": {
        "id": "YoVSqRURaaSN",
        "outputId": "acc4be0f-e600-428b-ddf8-6648330bbe1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question 1. {'score': 0.9882006645202637, 'start': 55, 'end': 66, 'answer': 'Los Angeles'}\n",
            "Question 2. {'score': 0.9880373477935791, 'start': 34, 'end': 51, 'answer': 'Pioneer Boulevard'}\n",
            "Question 3. {'score': 0.3341643810272217, 'start': 55, 'end': 66, 'answer': 'Los Angeles'}\n",
            "Question 4. {'score': 0.25206997990608215, 'start': 389, 'end': 398, 'answer': 'Las Vegas'}\n",
            "Question 5. {'score': 0.17297087609767914, 'start': 55, 'end': 66, 'answer': 'Los Angeles'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Person entity questions"
      ],
      "metadata": {
        "id": "exJMgYojZwvb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_qa = pipeline(\"question-answering\")"
      ],
      "metadata": {
        "id": "huwjibwwZxa6",
        "outputId": "78d47d5b-b551-4546-d9e4-72fb6d51592f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-cased-distilled-squad (https://huggingface.co/distilbert-base-cased-distilled-squad)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_qa(context=sequence, question=\"Who was singing?\")"
      ],
      "metadata": {
        "id": "6yL2b3MiaT_g",
        "outputId": "7ba92d70-b1fc-40d3-9718-170f8a4850e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': 'Nat King Cole',\n",
              " 'end': 278,\n",
              " 'score': 0.9848748445510864,\n",
              " 'start': 265}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_qa(context=sequence, question=\"Who was going to Las Vegas ?\")"
      ],
      "metadata": {
        "id": "IQ9COBq9aOw8",
        "outputId": "123f740b-c405-421e-ff27-c16d317ce09d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': 'Maria', 'end': 307, 'score': 0.5128909945487976, 'start': 302}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_qa(context=sequence, question=\"Who are they?\")"
      ],
      "metadata": {
        "id": "hGj7_zIbaeoP",
        "outputId": "6c4fbf18-2d23-45ff-db00-923a4985edbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': 'Nat King Cole',\n",
              " 'end': 278,\n",
              " 'score': 0.612321674823761,\n",
              " 'start': 265}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_qa(context=sequence, question=\"Who drove to Las Vegas?\")"
      ],
      "metadata": {
        "id": "itX3vv_daoRF",
        "outputId": "b8aafc4c-e90d-42d5-fc64-860735c19470",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': 'Maria', 'end': 307, 'score': 0.9794563055038452, 'start': 302}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the transformer\n",
        "faced a semantic labeling problem. \n",
        "\n",
        "Let’s try to do better with person entity questions applying\n",
        "an SRL-first method."
      ],
      "metadata": {
        "id": "rRb6wopja_vX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Method 2: SRL first"
      ],
      "metadata": {
        "id": "fwiV04JNa6yu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_qa(context=sequence, question=\"Who are they?\")"
      ],
      "metadata": {
        "id": "u6oHrX-Ta7mO",
        "outputId": "c47f9c5d-e405-4e0b-8a40-3f7222855448",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': 'Nat King Cole',\n",
              " 'end': 278,\n",
              " 'score': 0.612321674823761,\n",
              " 'start': 265}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_qa(context=sequence, question=\"Who drove to Las Vegas?\")"
      ],
      "metadata": {
        "id": "yk0DRAM00rPm",
        "outputId": "e495acd1-5201-4274-8ee4-ed18eda3186c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': 'Maria', 'end': 307, 'score': 0.9794563055038452, 'start': 302}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Question-answering with ELECTRA"
      ],
      "metadata": {
        "id": "o82VbZL-4IA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_qa = pipeline(\"question-answering\", model=\"google/electra-small-generator\", tokenizer=\"google/electra-small-generator\")"
      ],
      "metadata": {
        "id": "eXesQwlh4I5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_qa(context=sequence, question=\"Who drove to Las Vegas?\")"
      ],
      "metadata": {
        "id": "4QuQ7O0_4dQ8",
        "outputId": "73c88453-8309-40f7-f5d7-f2a788fbba52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': 'down on Pioneer Boulevard in Los Angeles, making it difficult to get out of',\n",
              " 'end': 101,\n",
              " 'score': 0.00039934273809194565,\n",
              " 'start': 26}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}